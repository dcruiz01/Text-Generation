{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rnn_char.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOiqoVO3G/1+xOnCwWn0lNl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zA_wx5EK3lGw"},"source":["# Character-level RNN for Text Generation\n","\n","The following project explores the creation of a recurrent neural network that generates text in the style of the provided corpus. For this experiment, the majority of former President Donald Trump's tweets from 2009 to 2021 will be used as training data. Final model output will be evaluated for similar in vocabulary, grammar, and tone to the training material."]},{"cell_type":"markdown","metadata":{"id":"-O381U-W4hvD"},"source":["### Environment"]},{"cell_type":"code","metadata":{"id":"qI_M_dSF02Kt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624636844776,"user_tz":240,"elapsed":24154,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"adafd652-d207-4deb-b2ee-849ad7cef633"},"source":["# general imports\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import sys\n","import io\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import re\n","import json\n","\n","# keras\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, GRU, InputLayer, LSTM, Bidirectional, SimpleRNN\n","from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","# connect to environment\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount = True)\n","    print(\"ENVIRONMENT: Google Drive\")\n","except:\n","    print(\"ENVIRONMENT: Local\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","ENVIRONMENT: Google Drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PGWS6ryx6bY8"},"source":["### Load Data & Preprocess"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"eFN8BrBt6oWE","executionInfo":{"status":"ok","timestamp":1624637160575,"user_tz":240,"elapsed":670,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"c052a14d-4c13-4be3-9fc0-63b60f51468b"},"source":["# read tweet csv\n","df = pd.read_csv('/content/drive/My Drive/RESEARCH/TEXT_GENERATION/data/trump_twitter_dataset/trump_train.csv')\n","print(df.shape)\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(40000, 9)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>isRetweet</th>\n","      <th>isDeleted</th>\n","      <th>device</th>\n","      <th>favorites</th>\n","      <th>retweets</th>\n","      <th>date</th>\n","      <th>isFlagged</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1006619872367804400</td>\n","      <td>I strongly endorse Adam Laxalt for Governor of...</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>Twitter for iPhone</td>\n","      <td>54668</td>\n","      <td>11776</td>\n","      <td>2018-06-12 19:30:54</td>\n","      <td>f</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1308870759469777000</td>\n","      <td>Diana Harshbarger (@DHarshbargerTN1) will be a...</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>Twitter for iPhone</td>\n","      <td>25880</td>\n","      <td>7268</td>\n","      <td>2020-09-23 20:48:01</td>\n","      <td>f</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>414554545608724500</td>\n","      <td>\"\"@SavingNancy: .@realDonaldTrump we raised $6...</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>Twitter for Android</td>\n","      <td>76</td>\n","      <td>51</td>\n","      <td>2013-12-22 00:34:40</td>\n","      <td>f</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>456128260741799940</td>\n","      <td>\"\"@NickySummer @AlexSalmond Wind farms are an ...</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>Twitter Web Client</td>\n","      <td>24</td>\n","      <td>26</td>\n","      <td>2014-04-15 17:53:46</td>\n","      <td>f</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>396359126395007000</td>\n","      <td>Via @IBTimes: \"\"Miss Universe 2013: Contestant...</td>\n","      <td>f</td>\n","      <td>f</td>\n","      <td>Twitter Web Client</td>\n","      <td>29</td>\n","      <td>27</td>\n","      <td>2013-11-01 19:32:34</td>\n","      <td>f</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    id  ... isFlagged\n","0  1006619872367804400  ...         f\n","1  1308870759469777000  ...         f\n","2   414554545608724500  ...         f\n","3   456128260741799940  ...         f\n","4   396359126395007000  ...         f\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoWk5-Lt6-JN","executionInfo":{"status":"ok","timestamp":1624637181694,"user_tz":240,"elapsed":726,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"a4ad31d3-fa7b-4f7d-eb35-8779fc98111a"},"source":["# extract tweets & build corpus\n","corp = ' '.join([x for x in df['text']])\n","print('BEFORE: ' + corp[:100])\n","\n","# make lowercase, remove non-alphabetic characters\n","corp = ' '.join(re.sub('[^a-z]+', ' ', corp.lower()).split())\n","print('AFTER: ' + corp[:100])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["BEFORE: I strongly endorse Adam Laxalt for Governor of Nevada. Adam is smart, works hard, and knows how to w\n","AFTER: i strongly endorse adam laxalt for governor of nevada adam is smart works hard and knows how to win \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rFYWpTRP7CNI","executionInfo":{"status":"ok","timestamp":1624637191953,"user_tz":240,"elapsed":119,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"e14cbc88-35c0-4f9d-8560-60d71b61bed7"},"source":["# get all unique characters\n","print('Corpus Length: ' + str(len(corp)) + ' characters.')\n","chars = sorted(list(set(corp)))\n","print('Total Unique Characters: ' + str(len(chars)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Corpus Length: 4797090 characters.\n","Total Unique Characters: 27\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bP5WIVor7E3d","executionInfo":{"status":"ok","timestamp":1624637200281,"user_tz":240,"elapsed":119,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}}},"source":["# create dictionaries that map from char to int / int to char (used to swap between character & one-hot encodings later)\n","char_i = dict((c, i) for i, c in enumerate(chars))\n","i_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILZNuAT27GUv","executionInfo":{"status":"ok","timestamp":1624637221481,"user_tz":240,"elapsed":136,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"082d6cee-5d5c-4047-f2d2-c601bd797c90"},"source":["# split corpus into sequences\n","maxlen = 20 # determines the length of character sequences used for training\n","step = 100 # how many characters to skip between each extracted sequence (to sample full corpus)\n","seqs = []\n","next_chars = []\n","\n","for i in range(0, len(corp) - maxlen, step):\n","  seqs.append(corp[i: i + maxlen]) # training data\n","  next_chars.append(corp[i + maxlen]) # target values\n","\n","print('Total Sequences Generated: ' + str(len(seqs)) + '.')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Total Sequences Generated: 47971.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itc3qWzX7Myc","executionInfo":{"status":"ok","timestamp":1624637233842,"user_tz":240,"elapsed":384,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"c2e90cca-8924-4de0-8613-f5312d228d8d"},"source":["# One-Hot Encoding\n","x = np.zeros((len(seqs), maxlen, len(chars)), dtype = np.bool)\n","y = np.zeros((len(seqs), len(chars)), dtype = np.bool)\n","for i, seq in enumerate(seqs):\n","  for t, char in enumerate(seq):\n","    x[i, t, char_i[char]] = 1\n","  y[i, char_i[next_chars[i]]] = 1\n","\n","print(x.shape, y.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(47971, 20, 27) (47971, 27)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hGeqtjzW7RVD"},"source":["### Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsNFFVE77S1Y","executionInfo":{"status":"ok","timestamp":1624637266345,"user_tz":240,"elapsed":1683,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"6fb26b14-da2a-4ae5-cbfc-8b2cd1a39625"},"source":["# define architecture\n","model = Sequential()\n","model.add(LSTM(24, return_sequences = True, input_shape = (maxlen, len(chars))))\n","model.add(LSTM(24, return_sequences = True))\n","model.add(LSTM(24, return_sequences = True))\n","model.add(LSTM(24))\n","model.add(Dense(len(chars), activation = 'softmax')) # one output neuron per unique character\n","model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 20, 24)            4992      \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 20, 24)            4704      \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 20, 24)            4704      \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 24)                4704      \n","_________________________________________________________________\n","dense (Dense)                (None, 27)                675       \n","=================================================================\n","Total params: 19,779\n","Trainable params: 19,779\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4c8iQe5U7ZAT","executionInfo":{"status":"ok","timestamp":1624637337893,"user_tz":240,"elapsed":132,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}}},"source":["# CALLBACKS\n","\n","# returns the index of a predicted character (for LambdaCallback)\n","def sample(preds):\n","  preds = np.asarray(preds).astype('float64')\n","  preds = np.log(preds)\n","  exp_preds = np.exp(preds)\n","  preds = exp_preds / np.sum(exp_preds)\n","  probas = np.random.multinomial(1, preds, 1)\n","  return np.argmax(probas)\n","\n","# generates text after each epoch (for LambdaCallback)\n","def on_epoch_end(epoch, logs):\n","  print()\n","  print('----- Generating text after Epoch: %d' % epoch)\n","  seed_length = 20\n","  start_index = np.random.randint(0, len(corp) - seed_length - 1)\n","  generated = ''\n","  segment = corp[start_index: start_index + seed_length]\n","  generated = generated + segment\n","  print('----- Generating with seed: \"' + segment + '\"')\n","  sys.stdout.write(generated)\n","  for i in range(140):\n","    x_pred = np.zeros((1, maxlen, len(chars)))\n","    for t, char in enumerate(segment):\n","        x_pred[0, t, char_i[char]] = 1.\n","\n","    preds = model.predict(x_pred, verbose=0)[0]\n","    next_index = sample(preds)\n","    next_char = i_char[next_index]\n","\n","    generated += next_char\n","    segment = segment[1:] + next_char\n","\n","    sys.stdout.write(next_char)\n","    sys.stdout.flush()\n","\n","# LambdaCallback will generate text using custom function after each epoch\n","A = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","# ModelCheckpoint callback will save model with the lowest achieved validation loss\n","B = ModelCheckpoint(filepath = '/content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5', save_best_only = True, verbose = 1)\n","\n","# EarlyStopping callback will stop training after a certain threshold is reached\n","C = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10, min_delta = .001, restore_best_weights=True)\n","\n","# ReduiceLROnPlateau callback will reduce learning rate given certain criteria to assist with convergence on local minima\n","D = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', factor = 0.1, verbose = 1, min_delta = .001, patience = 5)\n","\n","# package callback functions into variable\n","cb_list = [A, B, C, D]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0yXyGl17nvM","executionInfo":{"status":"ok","timestamp":1624640413769,"user_tz":240,"elapsed":3061030,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"a29e3697-2cf5-4df7-a08a-bf6c9898d032"},"source":["history = model.fit(x, y, batch_size = 32, epochs = 100, validation_split = 0.2, verbose = 1, callbacks = cb_list, shuffle = True)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1200/1200 [==============================] - 50s 36ms/step - loss: 2.9025 - accuracy: 0.1789 - val_loss: 2.8874 - val_accuracy: 0.1792\n","\n","----- Generating text after Epoch: 0\n","----- Generating with seed: \"d for u s amp china \"\n","d for u s amp china h   e ntydd gttg cfot aez s  tp mn n yb z toohuetgg neey rl tt  itlsupdouoxa  tuh eh datatpamwets logsmdt edeng n e irhri v tbbhnyor riii go\n","Epoch 00001: val_loss improved from inf to 2.88745, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 2/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.8691 - accuracy: 0.1815 - val_loss: 2.7909 - val_accuracy: 0.1956\n","\n","----- Generating text after Epoch: 1\n","----- Generating with seed: \"weet me back thanks \"\n","weet me back thanks tetsueut aaatsghngtgja emcitreapmoesiouamlaselmht c wza nci adoam tcaeaaoal rltet ws eef ee sss nktie a ntnpfriivltnartrantts os dvdn ekit e\n","Epoch 00002: val_loss improved from 2.88745 to 2.79092, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 3/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.7270 - accuracy: 0.2222 - val_loss: 2.6783 - val_accuracy: 0.2273\n","\n","----- Generating text after Epoch: 2\n","----- Generating with seed: \"oked hillary can off\"\n","oked hillary can offi aran lgs otrtn jrlshn tooe toa lacrrcnv baiile loaad nakrnsirsts ray tgrmtre wkacus im tyse poan pygsrie heteus matny ln ntd dap shpearn a\n","Epoch 00003: val_loss improved from 2.79092 to 2.67831, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 4/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.6091 - accuracy: 0.2516 - val_loss: 2.5229 - val_accuracy: 0.2795\n","\n","----- Generating text after Epoch: 3\n","----- Generating with seed: \"rnor of georgia both\"\n","rnor of georgia bothek wocchy amse fidapnton diosd on s oeal hreesass masrdaonye ivin xhafmwrtegbleie res res wolmon wes worl dopec og nleon corg mos bo ianys t\n","Epoch 00004: val_loss improved from 2.67831 to 2.52285, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 5/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.4770 - accuracy: 0.2838 - val_loss: 2.4450 - val_accuracy: 0.2917\n","\n","----- Generating text after Epoch: 4\n","----- Generating with seed: \"contents of my perfe\"\n","contents of my perfeseiart to iley in amibr orirlep iodiley brifn tho f whad w r milh mod gripiace geay fece o gtima ont mrele gameedty peeen metattat hh to hoe\n","Epoch 00005: val_loss improved from 2.52285 to 2.44498, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 6/100\n","1200/1200 [==============================] - 45s 37ms/step - loss: 2.4125 - accuracy: 0.2994 - val_loss: 2.4099 - val_accuracy: 0.3046\n","\n","----- Generating text after Epoch: 5\n","----- Generating with seed: \"xandfriends thank yo\"\n","xandfriends thank yoiaset reave tes gage thime nocogisk weed tralameivamtlleteibe wativhinturd bedispsethot beulhininosimoluvrel hine thart feut nole dmobp wese\n","Epoch 00006: val_loss improved from 2.44498 to 2.40994, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 7/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.3639 - accuracy: 0.3149 - val_loss: 2.3539 - val_accuracy: 0.3228\n","\n","----- Generating text after Epoch: 6\n","----- Generating with seed: \"metogettough wikilea\"\n","metogettough wikileaghonitaad peoleudac atlra vhe taatolonirw aod wis ozure wirlere vos btant anla seledinh soaa hulw i res lotasr yanthintime wira it yha the t\n","Epoch 00007: val_loss improved from 2.40994 to 2.35388, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 8/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.3193 - accuracy: 0.3297 - val_loss: 2.3206 - val_accuracy: 0.3264\n","\n","----- Generating text after Epoch: 7\n","----- Generating with seed: \"and is pro life kay \"\n","and is pro life kay cyean he hot porlen gen case hy deoll loce to milie as moca iod tath ull yee th gun holt the bame ontr ganlty cpurt omelr orime tho thp peor\n","Epoch 00008: val_loss improved from 2.35388 to 2.32062, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 9/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.2829 - accuracy: 0.3396 - val_loss: 2.2847 - val_accuracy: 0.3442\n","\n","----- Generating text after Epoch: 8\n","----- Generating with seed: \"erm financing withou\"\n","erm financing withount wha tho inw horlen btor we bed docet m priny ceaegs semelnowa a ol carany basd o that higlong viuch sramty ruekon folticatonad yeel itarl\n","Epoch 00009: val_loss improved from 2.32062 to 2.28473, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 10/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.2473 - accuracy: 0.3483 - val_loss: 2.3070 - val_accuracy: 0.3359\n","\n","----- Generating text after Epoch: 9\n","----- Generating with seed: \"other procedures at \"\n","other procedures at den the deny pead a pilirn lol doss roug wo ile to mo ren d st miut pame wen as billerh on oce locun srruag in hhe he dejpint jart iald gouk\n","Epoch 00010: val_loss did not improve from 2.28473\n","Epoch 11/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 2.2186 - accuracy: 0.3585 - val_loss: 2.2291 - val_accuracy: 0.3590\n","\n","----- Generating text after Epoch: 10\n","----- Generating with seed: \"amp the dnc which th\"\n","amp the dnc which thran tonrawtracd ba to thor wret lriagarore troysey pin for frepen dreoverta as suolinl peotcons nhes of whe vovint the hic poredores andy be\n","Epoch 00011: val_loss improved from 2.28473 to 2.22907, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 12/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.1921 - accuracy: 0.3652 - val_loss: 2.2218 - val_accuracy: 0.3552\n","\n","----- Generating text after Epoch: 11\n","----- Generating with seed: \"t appearance on squa\"\n","t appearance on squacdard suy to jento fitinnt hor inring crucil the lrute corige cawt ale to was slo way sealsd is un ale docanly eicidanst hhagt tincieg and c\n","Epoch 00012: val_loss improved from 2.22907 to 2.22178, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 13/100\n","1200/1200 [==============================] - 45s 37ms/step - loss: 2.1664 - accuracy: 0.3720 - val_loss: 2.1912 - val_accuracy: 0.3700\n","\n","----- Generating text after Epoch: 12\n","----- Generating with seed: \"rsary of the people \"\n","rsary of the people rolenni niile an onan amest then gia emils s pead  om wis ams tadmorgingss fabol hap seledars regird the net eleres ronis your geets http t \n","Epoch 00013: val_loss improved from 2.22178 to 2.19118, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 14/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.1432 - accuracy: 0.3756 - val_loss: 2.1756 - val_accuracy: 0.3707\n","\n","----- Generating text after Epoch: 13\n","----- Generating with seed: \" all overwhelming fo\"\n"," all overwhelming for fhy winnotifr uuwbe hatty the mouded nass hat nols barbinniaud nugp a sawde for fod medtint inder seaticole anduntsey dopingos peorla an r\n","Epoch 00014: val_loss improved from 2.19118 to 2.17557, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 15/100\n","1200/1200 [==============================] - 44s 36ms/step - loss: 2.1222 - accuracy: 0.3817 - val_loss: 2.1745 - val_accuracy: 0.3714\n","\n","----- Generating text after Epoch: 14\n","----- Generating with seed: \" to express our full\"\n"," to express our fullound luns yoor sist joln sodent sy do eftere ad a mlatse voves wirlerire nosgy mollifigosiogin wos pean trruxt g gom thieks ct han it erente\n","Epoch 00015: val_loss improved from 2.17557 to 2.17455, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 16/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 2.1017 - accuracy: 0.3862 - val_loss: 2.1438 - val_accuracy: 0.3832\n","\n","----- Generating text after Epoch: 15\n","----- Generating with seed: \"rrupt places on eart\"\n","rrupt places on earta eftor tr remyan the a s seemien onsey enem os litbenting as des wade gunsc husive be rusa me biwluld be wigl stay ryr wac leematbing grolm\n","Epoch 00016: val_loss improved from 2.17455 to 2.14384, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 17/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 2.0835 - accuracy: 0.3888 - val_loss: 2.1267 - val_accuracy: 0.3792\n","\n","----- Generating text after Epoch: 16\n","----- Generating with seed: \"t emmys were awful s\"\n","t emmys were awful sorpingfes ural foua habhos hins jey thened hhore gitivan luvite yoo deeging the tru poey subed rolaten theult mtebce in beuning h landor mav\n","Epoch 00017: val_loss improved from 2.14384 to 2.12666, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 18/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 2.0676 - accuracy: 0.3940 - val_loss: 2.1197 - val_accuracy: 0.3841\n","\n","----- Generating text after Epoch: 17\n","----- Generating with seed: \" people and today i \"\n"," people and today i mukhtint for rishey thing ebind bttpre osoir the wosas can haba hig lust doleioby and at pasach to all for ggising hosper bato harled we i r\n","Epoch 00018: val_loss improved from 2.12666 to 2.11971, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 19/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 2.0519 - accuracy: 0.3969 - val_loss: 2.1176 - val_accuracy: 0.3858\n","\n","----- Generating text after Epoch: 18\n","----- Generating with seed: \" z rudtg fed there i\"\n"," z rudtg fed there ire and croame rearall on it s bxtoald thinsige world wtarl the taloles couga at dea let tarlre wis eman eleir eirria we dos ovaldtrol anh cl\n","Epoch 00019: val_loss improved from 2.11971 to 2.11757, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 20/100\n","1200/1200 [==============================] - 44s 36ms/step - loss: 2.0367 - accuracy: 0.4010 - val_loss: 2.0917 - val_accuracy: 0.3941\n","\n","----- Generating text after Epoch: 19\n","----- Generating with seed: \"el almost complete g\"\n","el almost complete gom pos prencenss todep tirkerte m s at vuuped gounso um thatker rotciet onice hillcee corlatufe omtca fhe wttpss t coonubeg mv i hbibe won w\n","Epoch 00020: val_loss improved from 2.11757 to 2.09173, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 21/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 2.0229 - accuracy: 0.4040 - val_loss: 2.0862 - val_accuracy: 0.3916\n","\n","----- Generating text after Epoch: 20\n","----- Generating with seed: \"stees of penn state \"\n","stees of penn state amp lecetinsing stporcters more eas not wis juinh on soen can pony we kare sar faning than epan alllecrodhente chas it us pewatenn thank the\n","Epoch 00021: val_loss improved from 2.09173 to 2.08618, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 22/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 2.0092 - accuracy: 0.4081 - val_loss: 2.0728 - val_accuracy: 0.3958\n","\n","----- Generating text after Epoch: 21\n","----- Generating with seed: \"o tlc lpyip wewantmi\"\n","o tlc lpyip wewantmion bavamican dy munbontamed the belwfe live pead the the whin tarrakinen sakmthic he eportae o smorlsiness of lejerd vref wibe soming goms u\n","Epoch 00022: val_loss improved from 2.08618 to 2.07284, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 23/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.9957 - accuracy: 0.4107 - val_loss: 2.0759 - val_accuracy: 0.3967\n","\n","----- Generating text after Epoch: 22\n","----- Generating with seed: \"to go on with these \"\n","to go on with these live gamets vewailg i ransal sartiy hald can becoy stal hettimy they wrans yous eed a nempyroris usp ond enuswvy so cha si tas leurlute and \n","Epoch 00023: val_loss did not improve from 2.07284\n","Epoch 24/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.9823 - accuracy: 0.4144 - val_loss: 2.0659 - val_accuracy: 0.4017\n","\n","----- Generating text after Epoch: 23\n","----- Generating with seed: \"i fo thanks for voti\"\n","i fo thanks for votionunever degiga boter megit nrg gom gits hiw resarot worl peoblues of i natise reold ant trums dies the nramicluo bo soratentor  lemateg cai\n","Epoch 00024: val_loss improved from 2.07284 to 2.06592, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 25/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.9715 - accuracy: 0.4174 - val_loss: 2.0531 - val_accuracy: 0.4034\n","\n","----- Generating text after Epoch: 24\n","----- Generating with seed: \"ng instead of jeb we\"\n","ng instead of jeb weilt ches wich mpecide s sdibgen apprectorer i bow have bach spoeged neal it amp ry on tha to bew yoing or whe egelt a the licling is thange \n","Epoch 00025: val_loss improved from 2.06592 to 2.05308, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 26/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 1.9586 - accuracy: 0.4206 - val_loss: 2.0687 - val_accuracy: 0.4071\n","\n","----- Generating text after Epoch: 25\n","----- Generating with seed: \"e his name from jona\"\n","e his name from jonary seul on awhpt chimkits a v tallided the s ebemwion erave fodfiwh mettar oviin and of il for oun alter for as obwid me onartites hill to t\n","Epoch 00026: val_loss did not improve from 2.05308\n","Epoch 27/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.9485 - accuracy: 0.4245 - val_loss: 2.0461 - val_accuracy: 0.4055\n","\n","----- Generating text after Epoch: 26\n","----- Generating with seed: \"u support the death \"\n","u support the death pumlawpern dreacder dhelgausinamoland trump solledax ilcateny tham s it the mf ftd wipline the dmurs bas leiles demarishria frump ben atpela\n","Epoch 00027: val_loss improved from 2.05308 to 2.04613, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 28/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 1.9379 - accuracy: 0.4265 - val_loss: 2.0442 - val_accuracy: 0.4092\n","\n","----- Generating text after Epoch: 27\n","----- Generating with seed: \" starts today on low\"\n"," starts today on low of wo renering than is more willite fhu basindigf cespunge iraor s bedald and igcuntialse the ale wich kmere of be for s diw it you jisgey \n","Epoch 00028: val_loss improved from 2.04613 to 2.04423, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 29/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.9283 - accuracy: 0.4302 - val_loss: 2.0353 - val_accuracy: 0.4147\n","\n","----- Generating text after Epoch: 28\n","----- Generating with seed: \"ttps t co rbuxfdz w \"\n","ttps t co rbuxfdz w is faik parting since duvifion hloppost lekedors who datasie grrat yarion and movince foe whe dar to more a fer socal xistermau wis of mith \n","Epoch 00029: val_loss improved from 2.04423 to 2.03529, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 30/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.9191 - accuracy: 0.4337 - val_loss: 2.0239 - val_accuracy: 0.4116\n","\n","----- Generating text after Epoch: 29\n","----- Generating with seed: \"p like shawn johnson\"\n","p like shawn johnsont for nicly mitikg alkubs i hattronsiss mentanca moraldy our is http t co yocmbumjvj cof fep then puigan on courdite nake no hiw wom soucica\n","Epoch 00030: val_loss improved from 2.03529 to 2.02390, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 31/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.9092 - accuracy: 0.4369 - val_loss: 2.0300 - val_accuracy: 0.4124\n","\n","----- Generating text after Epoch: 30\n","----- Generating with seed: \"p college students l\"\n","p college students lukes shot eet ofefing beint in tougy ecliesruted canate and for sagel falal who naci https t co plmdvbypx is thone lons auit joonthiend wim \n","Epoch 00031: val_loss did not improve from 2.02390\n","Epoch 32/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.8992 - accuracy: 0.4385 - val_loss: 2.0263 - val_accuracy: 0.4109\n","\n","----- Generating text after Epoch: 31\n","----- Generating with seed: \"tps t co dz texpwf m\"\n","tps t co dz texpwf mameretiw joce ofpornte must yanghrocinivy form got doed hat sheis fon t hedmt wis bodating to uf is coes canshow bomtuphate nor to wand jatn\n","Epoch 00032: val_loss did not improve from 2.02390\n","Epoch 33/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.8911 - accuracy: 0.4403 - val_loss: 2.0139 - val_accuracy: 0.4230\n","\n","----- Generating text after Epoch: 32\n","----- Generating with seed: \"ganization and settl\"\n","ganization and settlangy that dibe the dics andrentor hanr nate underetering new iger wirlds let demtadaly fremidran oud of trselberssike we devary arenliing be\n","Epoch 00033: val_loss improved from 2.02390 to 2.01388, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 34/100\n","1200/1200 [==============================] - 45s 37ms/step - loss: 1.8810 - accuracy: 0.4433 - val_loss: 2.0122 - val_accuracy: 0.4194\n","\n","----- Generating text after Epoch: 33\n","----- Generating with seed: \"wol ibaw https t co \"\n","wol ibaw https t co bn lcnptk http t co hfnkpykr satery depentor http t co wcylpcohsm sige gusal a begy nays bin dyorl https t co ikt vdl xcy a donk afteps as t\n","Epoch 00034: val_loss improved from 2.01388 to 2.01217, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 35/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 1.8733 - accuracy: 0.4448 - val_loss: 2.0083 - val_accuracy: 0.4238\n","\n","----- Generating text after Epoch: 34\n","----- Generating with seed: \"u thank you arizona \"\n","u thank you arizona r su s are oven eet oud leing https t co k hscal hake neptoahcitmerly far http t co icv reitm ole be coonsandtrebs meniesled prome yan prise\n","Epoch 00035: val_loss improved from 2.01217 to 2.00829, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 36/100\n","1200/1200 [==============================] - 44s 36ms/step - loss: 1.8638 - accuracy: 0.4481 - val_loss: 2.0137 - val_accuracy: 0.4204\n","\n","----- Generating text after Epoch: 35\n","----- Generating with seed: \"air force one on the\"\n","air force one on the grekint obane of i to interturaating eebling all the of stillowiin kthluk nater in reminana bin net savenive rogest neinstews regif car ald\n","Epoch 00036: val_loss did not improve from 2.00829\n","Epoch 37/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.8559 - accuracy: 0.4499 - val_loss: 2.0115 - val_accuracy: 0.4217\n","\n","----- Generating text after Epoch: 36\n","----- Generating with seed: \"laints should immedi\"\n","laints should immedics you newtpy yoosks ay me my mordiog in riking you reeuone nentods nessos tho reladel inemest in wave poled sape semat ol that xat chare go\n","Epoch 00037: val_loss did not improve from 2.00829\n","Epoch 38/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.8484 - accuracy: 0.4525 - val_loss: 2.0057 - val_accuracy: 0.4262\n","\n","----- Generating text after Epoch: 37\n","----- Generating with seed: \"re in a much stronge\"\n","re in a much stronger mursings yor comn boss comettriterm tonal nara i vinged yass ente kowe wiul hctppet s to ilyncorry and in ectuuge amp was trist alman sing\n","Epoch 00038: val_loss improved from 2.00829 to 2.00570, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 39/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 1.8396 - accuracy: 0.4544 - val_loss: 2.0116 - val_accuracy: 0.4265\n","\n","----- Generating text after Epoch: 38\n","----- Generating with seed: \"un the trump empire \"\n","un the trump empire eiest nuundodenster pretite by tryeugincint fand geafers courting olcrie have couse lein amp resaced loin there proterif of plowect at teult\n","Epoch 00039: val_loss did not improve from 2.00570\n","Epoch 40/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.8310 - accuracy: 0.4561 - val_loss: 2.0038 - val_accuracy: 0.4250\n","\n","----- Generating text after Epoch: 39\n","----- Generating with seed: \"puyych bernie madoff\"\n","puyych bernie madoffodwnles oor pats of what objiggrentcent trump natersed that to s gem and bet we mlelating the bin bisslomiens doten mave bocr is the felr ev\n","Epoch 00040: val_loss improved from 2.00570 to 2.00377, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 41/100\n","1200/1200 [==============================] - 44s 36ms/step - loss: 1.8246 - accuracy: 0.4590 - val_loss: 2.0032 - val_accuracy: 0.4271\n","\n","----- Generating text after Epoch: 40\n","----- Generating with seed: \"ama said over and ov\"\n","ama said over and ove atery a leest at you four it pougt the realdoned impuct dem toal to trumppork forsh our t ihet and ladmed rod olw eom thppeet donwes apr o\n","Epoch 00041: val_loss improved from 2.00377 to 2.00319, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 42/100\n","1200/1200 [==============================] - 44s 36ms/step - loss: 1.8169 - accuracy: 0.4605 - val_loss: 2.0061 - val_accuracy: 0.4255\n","\n","----- Generating text after Epoch: 41\n","----- Generating with seed: \" senator claire mcca\"\n"," senator claire mccarlftangun intru ohd stalresy amp int bay reticfmrasd http t co worfih mk ton that conticed to want oht shath fereds your appomely will on fa\n","Epoch 00042: val_loss did not improve from 2.00319\n","Epoch 43/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.8097 - accuracy: 0.4640 - val_loss: 1.9973 - val_accuracy: 0.4320\n","\n","----- Generating text after Epoch: 42\n","----- Generating with seed: \" high on price with \"\n"," high on price with loter mmubved ampwunt for fisibe devering and yair nevamuda thank your onlees vericage hauke hises intusg dunnroce of the ofs a the sase toe\n","Epoch 00043: val_loss improved from 2.00319 to 1.99730, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 44/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.8034 - accuracy: 0.4649 - val_loss: 1.9971 - val_accuracy: 0.4328\n","\n","----- Generating text after Epoch: 43\n","----- Generating with seed: \"s endorsed the newsm\"\n","s endorsed the newsm eue trump prieed premats clovito lidenble awe yediced s sasters im aranl it theng to jundtronting hoirn trodidontind that sade wills wolcu \n","Epoch 00044: val_loss improved from 1.99730 to 1.99711, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 45/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7945 - accuracy: 0.4681 - val_loss: 2.0117 - val_accuracy: 0.4281\n","\n","----- Generating text after Epoch: 44\n","----- Generating with seed: \"au it s a beginning \"\n","au it s a beginning https t co eeoomucc em rois creurt shise is amhered wo money srow http t to crf vgheua https t co ityrprl m degidely suvenminentod cheles wi\n","Epoch 00045: val_loss did not improve from 1.99711\n","Epoch 46/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7899 - accuracy: 0.4690 - val_loss: 2.0252 - val_accuracy: 0.4254\n","\n","----- Generating text after Epoch: 45\n","----- Generating with seed: \"is going crazy they \"\n","is going crazy they a to for i neess an pnmayalancruted joa dack i haw lnver bords in then and leiet the kaok the jontt cins ow pike realdentaldtrump eord we re\n","Epoch 00046: val_loss did not improve from 1.99711\n","Epoch 47/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 1.7825 - accuracy: 0.4713 - val_loss: 2.0051 - val_accuracy: 0.4299\n","\n","----- Generating text after Epoch: 46\n","----- Generating with seed: \" fake news but becau\"\n"," fake news but becaulesseyting releearidal weenventake in hand we to detornactorented mefers dih wach to wat chinten schobt ofnia of it s by md cowe the wath a \n","Epoch 00047: val_loss did not improve from 1.99711\n","Epoch 48/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7738 - accuracy: 0.4724 - val_loss: 2.0084 - val_accuracy: 0.4295\n","\n","----- Generating text after Epoch: 47\n","----- Generating with seed: \"butler seth kossin h\"\n","butler seth kossin haw will thil of praying the mokal thes rost you biol the redent funry donvh efiget to for and the deal ving rack hops chitys thild oud of to\n","Epoch 00048: val_loss did not improve from 1.99711\n","\n","Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 49/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7329 - accuracy: 0.4835 - val_loss: 1.9924 - val_accuracy: 0.4342\n","\n","----- Generating text after Epoch: 48\n","----- Generating with seed: \" zibn https t co mgy\"\n"," zibn https t co mgyobobbbn thands bild on to hest the reguct a caure out tell nep not on they misthalcorest my feghlet amp don https t co lcyrypvvvs my ay than\n","Epoch 00049: val_loss improved from 1.99711 to 1.99237, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 50/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7253 - accuracy: 0.4862 - val_loss: 1.9916 - val_accuracy: 0.4325\n","\n","----- Generating text after Epoch: 49\n","----- Generating with seed: \"tion so much work ht\"\n","tion so much work https t co vn bg caart felt are ever thep aroinning ku hattering chimadion contrresilats in reslinbalnayd inheracl praymest covy his http t co\n","Epoch 00050: val_loss improved from 1.99237 to 1.99164, saving model to /content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5\n","Epoch 51/100\n","1200/1200 [==============================] - 44s 36ms/step - loss: 1.7231 - accuracy: 0.4864 - val_loss: 1.9928 - val_accuracy: 0.4338\n","\n","----- Generating text after Epoch: 50\n","----- Generating with seed: \"s poll numbers are i\"\n","s poll numbers are incorsissana thingst wy se mused a a realnyhorlmwe what to yet muet aralko dumt rebirlse world idtumre the whe depiving nrsirlifd bis arestoc\n","Epoch 00051: val_loss did not improve from 1.99164\n","Epoch 52/100\n","1200/1200 [==============================] - 44s 36ms/step - loss: 1.7213 - accuracy: 0.4873 - val_loss: 1.9940 - val_accuracy: 0.4328\n","\n","----- Generating text after Epoch: 51\n","----- Generating with seed: \"s a fighter for new \"\n","s a fighter for new heillary dare prandountrrrpeuld missoy sume dan apprectrcpmente realdrong ping thanulyswtny ampposer it no sayispiress i than you my ust wal\n","Epoch 00052: val_loss did not improve from 1.99164\n","Epoch 53/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7200 - accuracy: 0.4878 - val_loss: 1.9953 - val_accuracy: 0.4332\n","\n","----- Generating text after Epoch: 52\n","----- Generating with seed: \" complete and total \"\n"," complete and total and iremtty sada clearoricn a ntarded imtory all trump streentor is sruela s of bagpacies im sitls tas amp pomione awame ursion nistilau pom\n","Epoch 00053: val_loss did not improve from 1.99164\n","Epoch 54/100\n","1200/1200 [==============================] - 45s 38ms/step - loss: 1.7186 - accuracy: 0.4880 - val_loss: 1.9942 - val_accuracy: 0.4338\n","\n","----- Generating text after Epoch: 53\n","----- Generating with seed: \" increases kennymaca\"\n"," increases kennymacare his gree the nets the whinuyer arle ond lets lost the leobon and a care worra onsorf alain daco eer cialy sol in retaeded arlaclandsty wu\n","Epoch 00054: val_loss did not improve from 1.99164\n","\n","Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 55/100\n","1200/1200 [==============================] - 45s 38ms/step - loss: 1.7133 - accuracy: 0.4893 - val_loss: 1.9942 - val_accuracy: 0.4338\n","\n","----- Generating text after Epoch: 54\n","----- Generating with seed: \"t enough to vote by \"\n","t enough to vote by olentors thank jord a not rint the lose morlatenticacahpaw whon t lett they of the whhttps t co lrhcsph aif ugettice very ban is lededent tr\n","Epoch 00055: val_loss did not improve from 1.99164\n","Epoch 56/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7125 - accuracy: 0.4895 - val_loss: 1.9945 - val_accuracy: 0.4334\n","\n","----- Generating text after Epoch: 55\n","----- Generating with seed: \"bc will officially a\"\n","bc will officially and bttps t co gcksg s co dabria prasting the wy toxes tepilatasionmandends ud atrrevy and walre toee so siccess and ewiile sass for bissody \n","Epoch 00056: val_loss did not improve from 1.99164\n","Epoch 57/100\n","1200/1200 [==============================] - 43s 36ms/step - loss: 1.7123 - accuracy: 0.4897 - val_loss: 1.9945 - val_accuracy: 0.4330\n","\n","----- Generating text after Epoch: 56\n","----- Generating with seed: \" caught on camera hi\"\n"," caught on camera hiluriny a bevone aresa jratuy is to bucby our to kucl se uve zot how dewems dondew weumy pustner soat tolalitaga firfer the had ands yon eeed\n","Epoch 00057: val_loss did not improve from 1.99164\n","Epoch 58/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7120 - accuracy: 0.4895 - val_loss: 1.9946 - val_accuracy: 0.4330\n","\n","----- Generating text after Epoch: 57\n","----- Generating with seed: \"d rather it be here \"\n","d rather it be here nusp nepefewacry me radestermies gits ghine prosettes hand are tomentitice bualme traw donilg s streol ktmppage that they mikes that the wil\n","Epoch 00058: val_loss did not improve from 1.99164\n","Epoch 59/100\n","1200/1200 [==============================] - 44s 37ms/step - loss: 1.7119 - accuracy: 0.4900 - val_loss: 1.9947 - val_accuracy: 0.4337\n","\n","----- Generating text after Epoch: 58\n","----- Generating with seed: \"the whole russia hoa\"\n","the whole russia hoa s rin as will woy you teusted realdronlaldtrump vatice great ementornyer becahe intidenticn af sprealson cen my bead they utmigateley worde\n","Epoch 00059: val_loss did not improve from 1.99164\n","Restoring model weights from the end of the best epoch.\n","\n","Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 00059: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"QOGUniu5e9Td","executionInfo":{"status":"ok","timestamp":1624646638622,"user_tz":240,"elapsed":386,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"466838c0-25ff-4a1a-a9d5-99e78ba4f5f6"},"source":["# Plot test/val loss\n","loss = history.history['loss']\n","v_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","\n","plt.figure()\n","plt.plot(epochs, loss, 'b', label = 'Training Loss.')\n","plt.plot(epochs, v_loss, 'g', label = 'Val Loss.')\n","plt.title ('Training vs. Validation Loss')\n","plt.legend()\n","plt.show()\n","\n","print('Maximum Validation Accuracy Achieved: ' + str(max(history.history['val_accuracy'])))"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Maximum Validation Accuracy Achieved: 0.4341844618320465\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LNHwJ4age8xV"},"source":["### Evaluate"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SpO84gkXzek","executionInfo":{"status":"ok","timestamp":1624647455803,"user_tz":240,"elapsed":6865,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"69424d9b-557a-4e43-840f-b1c71440bf02"},"source":["# preprocess test data as above\n","df = pd.read_csv('/content/drive/My Drive/RESEARCH/TEXT_GENERATION/data/trump_twitter_dataset/trump_test.csv')\n","corp = ' '.join([x for x in df['text']])\n","corp = ' '.join(re.sub('[^a-z]+', ' ', corp.lower()).split())\n","char_i = dict((c, i) for i, c in enumerate(chars))\n","i_char = dict((i, c) for i, c in enumerate(chars))\n","maxlen = 20\n","step = 1\n","seqs = []\n","next_chars = []\n","for i in range(0, len(corp) - maxlen, step):\n","  seqs.append(corp[i: i + maxlen])\n","  next_chars.append(corp[i + maxlen])\n","print('Total Test Sequences: ' + str(len(seqs)) + '.')\n","x_test = np.zeros((len(seqs), maxlen, len(chars)), dtype = np.bool)\n","y_test = np.zeros((len(seqs), len(chars)), dtype = np.bool)\n","for i, seq in enumerate(seqs):\n","  for t, char in enumerate(seq):\n","    x_test[i, t, char_i[char]] = 1\n","  y_test[i, char_i[next_chars[i]]] = 1\n","print(x_test.shape, y_test.shape)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Total Test Sequences: 810960.\n","(810960, 20, 27) (810960, 27)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"owJ7Uf8YiObe","executionInfo":{"status":"ok","timestamp":1624647576518,"user_tz":240,"elapsed":1468,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}}},"source":["# load model\n","test_model = load_model('/content/drive/My Drive/RESEARCH/TEXT_GENERATION/models/rnn_char_model.hdf5')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3iNJIYfirZ9","executionInfo":{"status":"ok","timestamp":1624647838302,"user_tz":240,"elapsed":224663,"user":{"displayName":"Daniel Ruiz","photoUrl":"","userId":"00785095761915236572"}},"outputId":"cb261d1b-0f06-40f0-a637-8fed9f09440e"},"source":["test_model.evaluate(x_test, y_test, verbose = 1)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["25343/25343 [==============================] - 225s 9ms/step - loss: 1.9928 - accuracy: 0.4312\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.9928113222122192, 0.4311828017234802]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"XrZa7RwMjADE"},"source":["### Preliminary Findings:\n","* Test Accuracy: 43.12%\n","* Sample Sequences Produced:\n","\n","1. the whole russia hoa s rin as will woy you teusted realdronlaldtrump vatice great ementornyer becahe intidenticn af sprealson cen my bead they utmigateley worde\n","2. d rather it be here nusp nepefewacry me radestermies gits ghine prosettes hand are tomentitice bualme traw donilg s streol ktmppage that they mikes that the wil\n","3. caught on camera hiluriny a bevone aresa jratuy is to bucby our to kucl se uve zot how dewems dondew weumy pustner soat tolalitaga firfer the had ands yon eeed\n","\n","* While final model accuracy was lower than expected, and generated sequences are largely nonsense, it's worth noting the model is able to produce *some* english words using an RNN tokenized with characters (as opposed to words) using only a small, proof-of-concept LSTM network.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GeWexSHjki21"},"source":["### Future Work\n","* Larger network, potential application of neural architecture search.\n","* Implement overfitting mitigation (regularization, recurrent dropout, etc).\n","* More sophisicated data preprocessing (remove urls, twitter handles, etc).\n","* Transition to word-level tokenization.\n","* Transition to transformer architecture."]},{"cell_type":"markdown","metadata":{"id":"TnK7I16j4mnZ"},"source":["### Acknowledgments\n","* Trump twitter dataset obtained from [Kaggle](https://https://www.kaggle.com/austinreese/trump-tweets).\n","* Code inspired by and partially derived from [Vishal Kumar's blog post](https://https://towardsdatascience.com/generating-text-using-a-recurrent-neural-network-1c3bfee27a5e) on a similar topic."]}]}